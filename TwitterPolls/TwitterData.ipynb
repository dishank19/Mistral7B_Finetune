{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "twtdata = pd.read_csv('reduced_dataset.csv', engine='pyarrow')\n",
    "# twtdata.head(20)\n",
    "twtdata = twtdata.dropna()\n",
    "\n",
    "twtdata = twtdata[twtdata['text'] != '']\n",
    "twtdata = twtdata.iloc[1000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = ENTER_API_KEY_HERE\n",
    "instruction_text = ''''The following is a block of text that is from a twitter poll. You have to classify it in one of the following categories: {'other', 'Social', 'political', 'economics', 'entertainment'}. Your reply must only contain one of these 5 words, ONE word only'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      gpt3_response     Human_Eval\n",
      "2588         Social          other\n",
      "2668      Economics          other\n",
      "3341  Entertainment  entertainment\n",
      "1353         Social          other\n",
      "3875          other         Social\n",
      "...             ...            ...\n",
      "1296  Entertainment  entertainment\n",
      "1377         Social          other\n",
      "2277  Entertainment  entertainment\n",
      "3542  Entertainment         Social\n",
      "2132  Entertainment  entertainment\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "len(twtdata)\n",
    "twtdata_sample = twtdata.sample(n=1000)\n",
    "twtdata_sample['combined_text'] = instruction_text + twtdata_sample['text'] + ' ' + twtdata_sample['polls'].astype(str)\n",
    "import openai\n",
    "openai.api_key = key\n",
    "\n",
    "def get_gpt4_response(text):\n",
    "    response = openai.Completion.create(\n",
    "      engine=\"text-davinci-003\",\n",
    "      prompt=text,\n",
    "      max_tokens=100\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "twtdata_sample['gpt4_response'] = twtdata_sample['combined_text'].apply(get_gpt4_response)\n",
    "\n",
    "print(twtdata_sample[['gpt3_response', 'Human_Eval']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'twtdata_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/dishankj/Documents/Umass Fall 23/CS_690F/Mistral7B_Finetune/TwitterData.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dishankj/Documents/Umass%20Fall%2023/CS_690F/Mistral7B_Finetune/TwitterData.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m twtdata_sample\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mfinal_dataframe.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'twtdata_sample' is not defined"
     ]
    }
   ],
   "source": [
    "twtdata_sample.to_csv('final_dataframe.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.46\n"
     ]
    }
   ],
   "source": [
    "twtdata_sample = pd.read_csv('final_dataframe.csv')\n",
    "\n",
    "# Encoding the 'Human_Eval' and 'gpt3_response' columns using one-hot encoding\n",
    "human_eval_encoded = pd.get_dummies(twtdata_sample['Human_Eval'], prefix='Human_Eval')\n",
    "gpt3_response_encoded = pd.get_dummies(twtdata_sample['gpt3_response'], prefix='gpt3_response')\n",
    "\n",
    "# Concatenating the original dataframe with the encoded dataframes\n",
    "twtdata_sample_encoded = pd.concat([twtdata_sample, human_eval_encoded, gpt3_response_encoded], axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Converting the 'Human_Eval' and 'gpt3_response' columns to string type\n",
    "twtdata_sample['Human_Eval'] = twtdata_sample['Human_Eval'].astype(str)\n",
    "twtdata_sample['gpt3_response'] = twtdata_sample['gpt3_response'].astype(str)\n",
    "# Calculating the accuracy score between 'Human_Eval' and 'gpt3_response'\n",
    "accuracy = accuracy_score(twtdata_sample['Human_Eval'], twtdata_sample['gpt3_response'])\n",
    "\n",
    "# Printing the accuracy score\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
